{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Italy Rent Prediction - XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import json\n",
                "import time\n",
                "import joblib\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "\n",
                "pd.options.display.float_format = '{:,.2f}'.format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_data = pd.read_csv('rents_clean.csv/rents_clean.csv')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Check which cols has the most null values\n",
                "df_data.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üìÅ LOADING DATA\")\n",
                "\n",
                "df_data = pd.read_csv('rents_clean.csv/rents_clean.csv')\n",
                "\n",
                "df_data.columns = ['region', 'city', 'neighborhood', 'price', 'datetime', 'parking spots',\n",
                "                   'bathrooms per room', 'bathrooms', 'rooms', 'top floor', 'condition',\n",
                "                   'energy class', 'sea view', 'central heating', 'area', 'furnished',\n",
                "                   'balcony', 'TV system', 'external exposure', 'fiber optic', 'electric gate',\n",
                "                   'cellar', 'shared garden', 'private garden', 'alarm system', 'doorman',\n",
                "                   'pool', 'villa', 'entire property', 'apartment', 'penthouse', 'loft', 'attic']\n",
                "\n",
                "\n",
                "# Filter by price\n",
                "df_filtered = df_data[(df_data['price'] < 4000) & (df_data['price'] > 0)].copy()\n",
                "\n",
                "# Filter by area\n",
                "df_filtered = df_filtered[df_filtered['area'] > 15]\n",
                "\n",
                "# Drop duplicates and missing values\n",
                "df_filtered = df_filtered.drop_duplicates()\n",
                "# Drop rows where critical info is missing\n",
                "df_filtered = df_filtered.dropna(subset=['price', 'area', 'city'])\n",
                "\n",
                "print(f\"‚úÖ Loaded {len(df_filtered)} rows. Starting cleaning...\")\n",
                "\n",
                "# Fill Boolean/Count features with 0\n",
                "cols_to_zero = ['central heating', 'parking spots', 'balcony', 'fiber optic', \n",
                "                'electric gate', 'cellar', 'shared garden', 'sea view', 'pool',\n",
                "                'furnished', 'top floor', 'external exposure']\n",
                "\n",
                "for col in cols_to_zero:\n",
                "    if col in df_filtered.columns:\n",
                "        df_filtered[col] = df_filtered[col].fillna(0)\n",
                "\n",
                "# Fill Numeric features with Median\n",
                "if 'rooms' in df_filtered.columns:\n",
                "    df_filtered['rooms'] = df_filtered['rooms'].fillna(df_filtered['rooms'].median())\n",
                "if 'bathrooms' in df_filtered.columns:\n",
                "    df_filtered['bathrooms'] = df_filtered['bathrooms'].fillna(df_filtered['bathrooms'].median())\n",
                "\n",
                "# Fill Categorical features with 'Unknown'\n",
                "cols_to_unknown = ['energy class', 'condition', 'neighborhood']\n",
                "for col in cols_to_unknown:\n",
                "    if col in df_filtered.columns:\n",
                "        df_filtered[col] = df_filtered[col].fillna('Unknown')\n",
                "\n",
                "# Keep only apartments\n",
                "df_filtered = df_filtered[df_filtered['apartment'] == 1]\n",
                "\n",
                "# Remove bathroom outliers (Relaxed to 3)\n",
                "df_filtered = df_filtered[df_filtered['bathrooms'] <= 3]\n",
                "\n",
                "# Fix energy class typos\n",
                "df_filtered = df_filtered[df_filtered['energy class'] != ',']\n",
                "\n",
                "# Drop unused columns\n",
                "cols_to_drop = ['TV system', 'alarm system', 'doorman', 'entire property', \n",
                "                'villa', 'penthouse', 'loft', 'attic', 'apartment', \n",
                "                'datetime', 'bathrooms per room', 'private garden']\n",
                "df_filtered.drop(columns=[c for c in cols_to_drop if c in df_filtered.columns], inplace=True)\n",
                "\n",
                "int_cols = ['bathrooms', 'rooms', 'parking spots', 'top floor', \n",
                "            'central heating', 'furnished', 'balcony', 'external exposure', \n",
                "            'fiber optic', 'electric gate', 'cellar', 'shared garden']\n",
                "\n",
                "# Fill any tiny remaining holes with 0 before converting\n",
                "for col in int_cols:\n",
                "    if col in df_filtered.columns:\n",
                "        df_filtered[col] = df_filtered[col].fillna(0).astype(int)\n",
                "\n",
                "# Encoding\n",
                "df_filtered = pd.get_dummies(df_filtered, columns=['energy class'], drop_first=True)\n",
                "\n",
                "print(\"üöÄ Data Successfully Cleaned!\")\n",
                "print(df_filtered.info())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Calculate Price per Sqm\n",
                "df_filtered['price_per_sqm'] = df_filtered['price'] / df_filtered['area']\n",
                "\n",
                "# 2. Calculate the Z-Score (How weird is this price for this city?)\n",
                "# We group by city because ‚Ç¨30/m¬≤ is normal in Milan but insane in a village.\n",
                "df_filtered['pps_zscore'] = df_filtered.groupby('city')['price_per_sqm'].transform(\n",
                "    lambda x: (x - x.mean()) / x.std()\n",
                ")\n",
                "\n",
                "# 3. View the Anomalies (Z-score > 3 means \"Statistical Freak\")\n",
                "anomalies = df_filtered[df_filtered['pps_zscore'] > 3]\n",
                "\n",
                "print(f\"Found {len(anomalies)} anomalies.\")\n",
                "# Print all anomalies\n",
                "print(anomalies[['price', 'area', 'city', 'price_per_sqm']].sort_values('price_per_sqm', ascending=False))\n",
                "\n",
                "# 4. Remove the Anomalies\n",
                "# We remove the anomalies to clean our data.\n",
                "df_filtered = df_filtered[df_filtered['pps_zscore'] <= 3]\n",
                "\n",
                "# 5. Verify the Cleaned Data\n",
                "print(f\"Data points after removing anomalies: {len(df_filtered)}\")\n",
                "print(df_filtered[['price', 'area', 'city', 'price_per_sqm']].describe())\n",
                "\n",
                "# 6. Remove the price_per_sqm column\n",
                "df_filtered = df_filtered.drop(columns=['price_per_sqm'])\n",
                "\n",
                "# 7. Remove the pps_zscore column\n",
                "df_filtered = df_filtered.drop(columns=['pps_zscore'])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log transform ONLY price\n",
                "df_filtered['price'] = np.log1p(df_filtered['price'])\n",
                "\n",
                "# Function to group rare categories\n",
                "def group_rare_categories(df, col, threshold):\n",
                "    counts = df[col].value_counts()\n",
                "    rare_values = counts[counts < threshold].index\n",
                "    # Faster than .replace() for large lists\n",
                "    df.loc[df[col].isin(rare_values), col] = 'Other'\n",
                "    return df\n",
                "\n",
                "# Apply it\n",
                "df_filtered = group_rare_categories(df_filtered, 'region', 1000)\n",
                "df_filtered = group_rare_categories(df_filtered, 'city', 300)\n",
                "df_filtered = group_rare_categories(df_filtered, 'neighborhood', 50)\n",
                "\n",
                "# Furnished and Central Heating interaction\n",
                "df_filtered['Furnished and Central Heating'] = np.where(\n",
                "    (df_filtered['furnished'] == 1) & (df_filtered['central heating'] == 1), 1, 0\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GEOCODING - ALL levels (region, city, neighborhood)\n",
                "print(\"\\nüåç Loading geocoding cache...\")\n",
                "\n",
                "cache_dir = 'geocoding_cache'\n",
                "\n",
                "def load_cache(filename):\n",
                "    path = os.path.join(cache_dir, filename)\n",
                "    if os.path.exists(path):\n",
                "        with open(path, 'r') as f:\n",
                "            coords = json.load(f)\n",
                "            return {k: tuple(v) if isinstance(v, list) else v for k, v in coords.items()}\n",
                "    return {}\n",
                "\n",
                "region_coordinates = load_cache('region_coordinates.json')\n",
                "city_coordinates = load_cache('city_coordinates.json')\n",
                "neighborhood_coordinates = load_cache('neighborhood_coordinates.json')\n",
                "\n",
                "# Region coordinates\n",
                "df_filtered['latitude'] = df_filtered['region'].map(lambda x: region_coordinates.get(x, region_coordinates.get('Other', (42, 12)))[0])\n",
                "df_filtered['longitude'] = df_filtered['region'].map(lambda x: region_coordinates.get(x, region_coordinates.get('Other', (42, 12)))[1])\n",
                "df_filtered.drop('region', axis=1, inplace=True)\n",
                "\n",
                "# City coordinates\n",
                "df_filtered['latitude_city'] = df_filtered['city'].map(lambda x: city_coordinates.get(x, city_coordinates.get('Other', (42, 12)))[0])\n",
                "df_filtered['longitude_city'] = df_filtered['city'].map(lambda x: city_coordinates.get(x, city_coordinates.get('Other', (42, 12)))[1])\n",
                "df_filtered = df_filtered.dropna(subset=['latitude_city', 'longitude_city'])\n",
                "df_filtered.drop('city', axis=1, inplace=True)\n",
                "\n",
                "# Neighborhood coordinates\n",
                "df_filtered['latitude_neighborhood'] = df_filtered['neighborhood'].map(\n",
                "    lambda x: neighborhood_coordinates.get(x, neighborhood_coordinates.get('Other', (42, 12)))[0]\n",
                ")\n",
                "df_filtered['longitude_neighborhood'] = df_filtered['neighborhood'].map(\n",
                "    lambda x: neighborhood_coordinates.get(x, neighborhood_coordinates.get('Other', (42, 12)))[1]\n",
                ")\n",
                "df_filtered.drop('neighborhood', axis=1, inplace=True)\n",
                "\n",
                "print(f\"‚úÖ Geocoding complete - {len(df_filtered)} rows remaining\")\n",
                "\n",
                "# One-hot encode condition\n",
                "encoded_df = pd.get_dummies(df_filtered, columns=['condition'], dtype=int, drop_first=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Interaction Features\n",
                "print(\"\\nüìä Adding feature interactions\")\n",
                "\n",
                "# Rooms per area ratio (density indicator)\n",
                "encoded_df['rooms_per_area'] = encoded_df['rooms'] / (encoded_df['area'] + 1)\n",
                "\n",
                "# Bathrooms per room ratio\n",
                "encoded_df['baths_per_room'] = encoded_df['bathrooms'] / (encoded_df['rooms'] + 1)\n",
                "\n",
                "# Amenity score (sum of binary features)\n",
                "amenity_cols = ['balcony', 'fiber optic', 'electric gate', 'shared garden', 'external exposure']\n",
                "encoded_df['amenity_score'] = encoded_df[amenity_cols].sum(axis=1)\n",
                "\n",
                "print(f\"   Added 3 interaction features\")\n",
                "print(f\"   Total features: {len(encoded_df.columns) - 1}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Stratified train/test split\n",
                "print(\"\\nüìä Stratified train/test split\")\n",
                "\n",
                "# Create price bins for stratification\n",
                "y_full = encoded_df['price']\n",
                "price_bins = pd.qcut(y_full, q=5, labels=['low', 'med_low', 'med', 'med_high', 'high'])\n",
                "\n",
                "X = encoded_df.drop('price', axis=1)\n",
                "y = encoded_df[['price']]\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=price_bins\n",
                ")\n",
                "\n",
                "print(f\"   Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"   Test set: {X_test.shape[0]} samples\")\n",
                "print(f\"   Features: {X_train.shape[1]}\")\n",
                "print(f\"   Feature names: {list(X_train.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"‚ö° XGBOOST FIXED TRAINING\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "xgb_model = xgb.XGBRegressor(\n",
                "    n_estimators=1500,      \n",
                "    max_depth=6,            \n",
                "    learning_rate=0.03,     \n",
                "    min_child_weight=4,     \n",
                "    subsample=0.7,          \n",
                "    colsample_bytree=0.7,   \n",
                "    gamma=0.5,              \n",
                "    reg_lambda=1.5,         \n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "print(f\"\\nüîß Hyperparameters:\")\n",
                "print(f\"   n_estimators: 500\")\n",
                "print(f\"   max_depth: 8\")\n",
                "print(f\"   learning_rate: 0.05\")\n",
                "print(f\"   min_child_weight: 3\")\n",
                "print(f\"   gamma: 0.1\")\n",
                "print(f\"   reg_alpha: 0.05\")\n",
                "print(f\"   reg_lambda: 0.5\")\n",
                "\n",
                "xgb_model.fit(X_train, y_train.values.ravel())\n",
                "\n",
                "elapsed_time = time.time() - start_time\n",
                "print(f\"\\n‚úÖ Training complete in {elapsed_time:.2f} seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb_train_score = xgb_model.score(X_train, y_train)\n",
                "xgb_test_score = xgb_model.score(X_test, y_test)\n",
                "\n",
                "print(f\"\\nüìà XGBoost FIXED Performance:\")\n",
                "print(f\"   Train R¬≤: {xgb_train_score:.4f}\")\n",
                "print(f\"   Test R¬≤:  {xgb_test_score:.4f}\")\n",
                "print(f\"   Gap:      {xgb_train_score - xgb_test_score:.4f}\")\n",
                "\n",
                "# Predictions\n",
                "xgb_train_pred = xgb_model.predict(X_train)\n",
                "xgb_test_pred = xgb_model.predict(X_test)\n",
                "\n",
                "# Convert to euros\n",
                "xgb_test_pred_euro = np.expm1(xgb_test_pred)\n",
                "y_test_euro = np.expm1(y_test.values.ravel())\n",
                "\n",
                "xgb_test_mae = mean_absolute_error(y_test_euro, xgb_test_pred_euro)\n",
                "xgb_test_rmse = np.sqrt(mean_squared_error(y_test_euro, xgb_test_pred_euro))\n",
                "\n",
                "print(f\"\\nüí∞ Error Metrics (in Euros):\")\n",
                "print(f\"   Test MAE:  ‚Ç¨{xgb_test_mae:.2f}\")\n",
                "print(f\"   Test RMSE: ‚Ç¨{xgb_test_rmse:.2f}\")\n",
                "\n",
                "# Overfitting check\n",
                "overfitting_gap = xgb_train_score - xgb_test_score\n",
                "if overfitting_gap < 0.05:\n",
                "    print(f\"\\n   ‚úÖ Excellent! Very low overfitting ({overfitting_gap:.4f})\")\n",
                "elif overfitting_gap < 0.08:\n",
                "    print(f\"\\n   ‚úÖ Good! Overfitting under control ({overfitting_gap:.4f})\")\n",
                "elif overfitting_gap < 0.12:\n",
                "    print(f\"\\n   ‚ö†Ô∏è  Mild overfitting ({overfitting_gap:.4f})\")\n",
                "else:\n",
                "    print(f\"\\n   ‚ùå Significant overfitting ({overfitting_gap:.4f})\")\n",
                "    \n",
                "results = pd.DataFrame({\n",
                "    'Actual': y_test_euro,\n",
                "    'Predicted': xgb_test_pred_euro\n",
                "})\n",
                "results['Error'] = results['Actual'] - results['Predicted']\n",
                "results['Abs_Error'] = abs(results['Error'])\n",
                "\n",
                "# Sort by biggest failures\n",
                "print(results.sort_values('Abs_Error', ascending=False).head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "xgb.plot_importance(xgb_model, max_num_features=15)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# HIGH RENT PERFORMANCE CHECK\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"üìä HIGH RENT (>‚Ç¨2000) PERFORMANCE CHECK\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "high_rent_mask = y_test_euro > 2000\n",
                "high_rent_actual = y_test_euro[high_rent_mask]\n",
                "high_rent_pred = xgb_test_pred_euro[high_rent_mask]\n",
                "\n",
                "if len(high_rent_actual) > 0:\n",
                "    high_rent_mae = mean_absolute_error(high_rent_actual, high_rent_pred)\n",
                "    high_rent_r2 = r2_score(high_rent_actual, high_rent_pred)\n",
                "    \n",
                "    print(f\"   High rent samples: {len(high_rent_actual)}\")\n",
                "    print(f\"   High rent MAE: ‚Ç¨{high_rent_mae:.2f}\")\n",
                "    print(f\"   High rent R¬≤: {high_rent_r2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CROSS-VALIDATION\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"üîÑ CROSS-VALIDATION\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "cv_scores = cross_val_score(xgb_model, X_train, y_train.values.ravel(), cv=5, scoring='r2', n_jobs=-1)\n",
                "print(f\"   CV R¬≤ Scores: {cv_scores.round(4)}\")\n",
                "print(f\"   Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# FEATURE IMPORTANCE\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"üìä FEATURE IMPORTANCE\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': X_train.columns,\n",
                "    'importance': xgb_model.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "print(\"\\nTop 10 Features:\")\n",
                "for i, row in feature_importance.head(10).iterrows():\n",
                "    print(f\"   {row['feature']}: {row['importance']:.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"üíæ SAVING MODEL\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "os.makedirs('rent_prediction_model', exist_ok=True)\n",
                "joblib.dump(xgb_model, 'rent_prediction_model/rent_model_v2.pkl')\n",
                "\n",
                "# Save feature names for reference\n",
                "feature_names = list(X_train.columns)\n",
                "with open('rent_prediction_model/feature_names.json', 'w') as f:\n",
                "    json.dump(feature_names, f, indent=2)\n",
                "\n",
                "print(f\"‚úÖ Model saved to rent_prediction_model/rent_model_v2.pkl\")\n",
                "print(f\"‚úÖ Feature names saved to rent_prediction_model/feature_names.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VISUALIZATIONS\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Actual vs Predicted\n",
                "ax1 = axes[0, 0]\n",
                "ax1.scatter(y_test_euro, xgb_test_pred_euro, alpha=0.3, s=10, color='orange')\n",
                "ax1.plot([0, 8000], [0, 8000], 'r--', label='Perfect')\n",
                "ax1.set_xlabel('Actual Rent (‚Ç¨)')\n",
                "ax1.set_ylabel('Predicted Rent (‚Ç¨)')\n",
                "ax1.set_title(f'Actual vs Predicted (R¬≤ = {xgb_test_score:.4f})')\n",
                "ax1.legend()\n",
                "\n",
                "# Residuals\n",
                "ax2 = axes[0, 1]\n",
                "residuals = xgb_test_pred_euro - y_test_euro\n",
                "ax2.scatter(xgb_test_pred_euro, residuals, alpha=0.3, s=10, color='orange')\n",
                "ax2.axhline(y=0, color='r', linestyle='--')\n",
                "ax2.set_xlabel('Predicted Rent (‚Ç¨)')\n",
                "ax2.set_ylabel('Residuals (‚Ç¨)')\n",
                "ax2.set_title('Residuals vs Predicted')\n",
                "\n",
                "# Residual Distribution\n",
                "ax3 = axes[1, 0]\n",
                "ax3.hist(residuals, bins=50, color='orange', edgecolor='black')\n",
                "ax3.axvline(x=0, color='r', linestyle='--')\n",
                "ax3.set_xlabel('Residual (‚Ç¨)')\n",
                "ax3.set_ylabel('Frequency')\n",
                "ax3.set_title(f'Residual Distribution (Mean: ‚Ç¨{residuals.mean():.2f})')\n",
                "\n",
                "# Feature Importance\n",
                "ax4 = axes[1, 1]\n",
                "top_features = feature_importance.head(15)\n",
                "ax4.barh(top_features['feature'], top_features['importance'], color='orange')\n",
                "ax4.set_xlabel('Importance')\n",
                "ax4.set_title('Top 15 Feature Importance')\n",
                "ax4.invert_yaxis()\n",
                "\n",
                "plt.suptitle('XGBoost FIXED - Model Performance', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
